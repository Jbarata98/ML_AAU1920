{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self study 1\n",
    "\n",
    "In this self study you should work on the code examples below together with the associated questions. The notebook illustrates a basic neural network implementation, where we implement most of the relevant functions from scratch. Except the calculation of gradients, for which we rely on the functionality provided by PyTorch. \n",
    "\n",
    "The code illustrates the key concepts involved in the learning neural network. Go carefully through the code before starting to answer the questions at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the code in the notebook is based on the tutorial at https://pytorch.org/tutorials/beginner/nn_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the modules used in this selfstudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database consists of grey scale images of handwritten digits. Each image is of size $28\\times 28$; see figure below for an illustration. The data set is divided into a training set, validation set, and test set consisting of $50000$, $10000$, and $10000$ images, respectively; in all data sets the images are labeled with the correct digits. If interested, you can find more information about the MNIST data set at http://yann.lecun.com/exdb/mnist/, including accuracy results for various machine learning methods.\n",
    "\n",
    "![MNIST DATA](MNIST-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download the dataset and unpackage it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then extract the data and store it numpy arrays: x_train, y_train, x_valid, y_valid, x_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), (x_test, y_test)) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $28 \\times 28$ images are stored in rows of length $784$, hence to display the images we need to reshape them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to take adavntage of PyTorch support for calculating gradients, we need to convert the numpy arrays to PyTorch tensors. See the code example from the last lecture on PyTorch's support for automatic gradient calculation using the back propagation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid, x_test, y_test)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "x_train, x_train.shape, y_train.min(), y_train.max()\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first part of this self study we will specify a neural network, which will encode a softmax function. For this we need a (randomly initialized) weight matrix and a bias, and for both of them we need their gradients wrt. our error function (yet to be defined) in order to perform learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784, 10) / np.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return x.exp() / x.exp().sum(-1).unsqueeze(-1)\n",
    "\n",
    "# Below @ refers to matrix multiplication\n",
    "def model(xb):\n",
    "    return softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our model (with our randomly initialized weights) using a so-called batch size of 64 (more on this later in the note book); for the prediction we pick out the first element in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([64, 784])\n",
      "Prediction on first image tensor([0.2092, 0.0717, 0.1460, 0.0516, 0.0964, 0.0504, 0.0961, 0.0894, 0.0992,\n",
      "        0.0900], grad_fn=<SelectBackward>)\n",
      "Corresponding classification: 0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "xb = x_train[0:batch_size]\n",
    "print(f\"Batch shape: {xb.shape}\")\n",
    "preds = model(xb)\n",
    "print(f\"Prediction on first image {preds[0]}\")\n",
    "print(f\"Corresponding classification: {preds[0].argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our loss function, in this case the log-loss (or negative log-likelihood):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return (-input[range(target.shape[0]), target].log()).mean()\n",
    "\n",
    "loss_func = nll\n",
    "\n",
    "# Make a test calculation\n",
    "yb = y_train[0:batch_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we are interested in the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model on batch (with random weights): 0.109375\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of model on batch (with random weights): {accuracy(preds, yb)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to combine it all and perform learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, B-idx: 0, Training loss: 2.2910988330841064\n",
      "Epoch: 0, B-idx: 100, Training loss: 0.8160584568977356\n",
      "Epoch: 0, B-idx: 200, Training loss: 0.6293962597846985\n",
      "Epoch: 0, B-idx: 300, Training loss: 0.5458772778511047\n",
      "Epoch: 0, B-idx: 400, Training loss: 0.5033016204833984\n",
      "Epoch: 0, B-idx: 500, Training loss: 0.4728817045688629\n",
      "Epoch: 0, B-idx: 600, Training loss: 0.4513234794139862\n",
      "Epoch: 0, B-idx: 700, Training loss: 0.4325897693634033\n",
      "Epoch: 1, B-idx: 0, Training loss: 0.4232078194618225\n",
      "Epoch: 1, B-idx: 100, Training loss: 0.412797749042511\n",
      "Epoch: 1, B-idx: 200, Training loss: 0.40462401509284973\n",
      "Epoch: 1, B-idx: 300, Training loss: 0.3947691321372986\n",
      "Epoch: 1, B-idx: 400, Training loss: 0.39016473293304443\n",
      "Epoch: 1, B-idx: 500, Training loss: 0.38275885581970215\n",
      "Epoch: 1, B-idx: 600, Training loss: 0.3778039515018463\n",
      "Epoch: 1, B-idx: 700, Training loss: 0.3711467683315277\n",
      "Epoch: 2, B-idx: 0, Training loss: 0.3682546019554138\n",
      "Epoch: 2, B-idx: 100, Training loss: 0.3648754954338074\n",
      "Epoch: 2, B-idx: 200, Training loss: 0.36225226521492004\n",
      "Epoch: 2, B-idx: 300, Training loss: 0.35714617371559143\n",
      "Epoch: 2, B-idx: 400, Training loss: 0.3563425838947296\n",
      "Epoch: 2, B-idx: 500, Training loss: 0.3521137833595276\n",
      "Epoch: 2, B-idx: 600, Training loss: 0.34980523586273193\n",
      "Epoch: 2, B-idx: 700, Training loss: 0.3458189070224762\n",
      "Epoch: 3, B-idx: 0, Training loss: 0.34416407346725464\n",
      "Epoch: 3, B-idx: 100, Training loss: 0.34258222579956055\n",
      "Epoch: 3, B-idx: 200, Training loss: 0.3415234088897705\n",
      "Epoch: 3, B-idx: 300, Training loss: 0.33787062764167786\n",
      "Epoch: 3, B-idx: 400, Training loss: 0.3382781147956848\n",
      "Epoch: 3, B-idx: 500, Training loss: 0.3352188766002655\n",
      "Epoch: 3, B-idx: 600, Training loss: 0.33381009101867676\n",
      "Epoch: 3, B-idx: 700, Training loss: 0.33097922801971436\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 4  # how many epochs to train for\n",
    "lr = 0.05  # learning rate\n",
    "\n",
    "start = time.time()\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "momentum = 0.9\n",
    "v = 0\n",
    "v_bias = 0\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx in range((n - 1) // batch_size + 1):\n",
    "        start_i = batch_idx * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        #m = torch.nn.Dropout(p=0.2)\n",
    "        #input = m(pred)\n",
    "        loss = loss_func(pred, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            #v = momentum * v -lr *(weights.grad) ## momentum not sure if well implemented\n",
    "            weights+=v\n",
    "            #print(weights)\n",
    "            #v_bias = momentum * v_bias -lr *(bias.grad)\n",
    "            bias -=  bias.grad*lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()     \n",
    "            if batch_idx % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                    train_loss = loss_func(model(x_train), y_train)\n",
    "                    print(f\"Epoch: {epoch}, B-idx: {batch_idx}, Training loss: {train_loss}\")\n",
    "                    train_losses.append(train_loss)\n",
    "                       # valid_loss = loss_func(model(x_valid), y_valid)\n",
    "                        #print(f\"Epoch: {epoch}, B-idx: {batch_idx}, valid loss: {valid_loss}\")\n",
    "                        #valid_losses.append(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the evolution of the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f041e167150>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_losses)), train_losses,'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ \n",
    "1. Experiment with different variations of the gradient descent implementation; try varying the learning rate and the batch size. Assuming that you have a fixed time budget (say 2 minutes for learning), what can we then say about the effect of changing the parameters?\n",
    "2. Implement momentum in the learning algorithm. How does it affect the results? \n",
    "3. Try with different initialization schemes for the parameters (e.g. allowing for larger values). How does it affect the behavior of the algorithm?\n",
    "4. Analyze the behavior of the algorithm on the test set and implement a method for evaluating the accuracy over the entire training/test set (for inspiration, see Line 21 above).\n",
    "\n",
    "NB: We didn't have time to cover momentum and batch sizes during the last lecture, so please revisit the slides/literature and try to get the gist of this on your own. We will discuss it further at the lecture on Thursday. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0261e-04, 1.6197e-07, 1.7623e-04,  ..., 9.9598e-01, 8.5512e-05,\n",
      "         1.6589e-03],\n",
      "        [9.9132e-03, 1.2259e-04, 8.9431e-01,  ..., 3.5899e-08, 6.7433e-03,\n",
      "         1.1007e-06],\n",
      "        [1.2085e-04, 9.5986e-01, 1.2925e-02,  ..., 4.3681e-03, 8.3249e-03,\n",
      "         1.3628e-03],\n",
      "        ...,\n",
      "        [2.3353e-06, 7.3057e-06, 7.9008e-05,  ..., 4.7297e-03, 1.3211e-02,\n",
      "         4.3089e-02],\n",
      "        [1.5362e-03, 3.5390e-03, 7.5067e-04,  ..., 4.6375e-04, 2.7682e-01,\n",
      "         7.8618e-04],\n",
      "        [3.3268e-04, 8.0757e-09, 1.0574e-03,  ..., 3.6392e-08, 5.3933e-06,\n",
      "         7.4387e-07]], grad_fn=<DivBackward0>)\n",
      "tensor([3, 8, 6,  ..., 5, 6, 8])\n",
      "Accuracy of model on batch (with random weights): 0.9132999777793884\n"
     ]
    }
   ],
   "source": [
    "pred_labels=model(x_test)\n",
    "print(pred_labels)\n",
    "print(y_valid)\n",
    "\n",
    "print(f\"Accuracy of model on batch (with random weights): {accuracy(pred_labels, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
