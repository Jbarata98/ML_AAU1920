{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyro'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f5e07c825bcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyro'"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import torch\n",
    "from pyro.optim import SGD, Adam\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "We consider the thumb tack model:\n",
    "\n",
    "<img src=\"https://www.moodle.aau.dk/pluginfile.php/1695750/mod_folder/content/0/thumb_tack.png?forcedownload=1\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the beta distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [(1,1), (2,2), (4,1),(2,5)]\n",
    "x = np.linspace(0,1,1000)\n",
    "plt.figure(figsize=(15, 5))\n",
    "for idx, para in enumerate(parameters):\n",
    "    plt.subplot(1, len(parameters), idx+1)\n",
    "    y = beta.pdf(x, *para)\n",
    "    plt.title(f'a={para[0]},b={para[1]}')\n",
    "    plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "Here we define the probabilistic model. Notice the close resemblance with the plate specification above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the thumb_tack model. The 'data' is a 0-1 tensor of type float  \n",
    "def thumb_tack_model(data):  \n",
    "    \n",
    "    # Define the random variable theta\n",
    "    theta = pyro.sample(\"theta\", dist.Beta(2.0,5.0))\n",
    "    \n",
    "    # and now the plate holding the observations. The number of observations are determined by the data set \n",
    "    # supplied to the function\n",
    "    with pyro.plate(\"thumb_tack_plate\"):\n",
    "        pyro.sample(f\"obs\", dist.Bernoulli(probs=theta), obs=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The variational distribution\n",
    "\n",
    "In Pyro the variational distribution is defined as a so-called guide. In this example our variational distribution is a beta distribution with parameters q_alpha and q_beta:\n",
    "\n",
    "$$\n",
    "q(\\theta)= \\mathit{Beta}(\\theta | \\alpha, \\beta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thumb_tack_guide(data):\n",
    "\n",
    "    # We initialize the variational parameters q_alpha and q_beta to 1.0. Also, we constrain the parameters to be positive as per \n",
    "    # definition of the distribution\n",
    "    q_alpha = pyro.param(\"q_alpha\", torch.tensor(1.0), constraint=constraints.positive)\n",
    "    q_beta = pyro.param(\"q_beta\", torch.tensor(1.0), constraint=constraints.positive)\n",
    "\n",
    "    # The name of the random variable of the variational distribution must match the name of the corresponding\n",
    "    # variable in the model exactly.\n",
    "    pyro.sample(\"theta\", dist.Beta(q_alpha, q_beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "\n",
    "For optimizing the ELBO we rely on a standard stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thumb_tack_learn(data):\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    # Define the ELBO and the optimization function\n",
    "    elbo = pyro.infer.Trace_ELBO()\n",
    "    svi = pyro.infer.SVI(model=thumb_tack_model,\n",
    "                         guide=thumb_tack_guide,\n",
    "                         optim=SGD({'lr':0.001}),\n",
    "                         loss=elbo)\n",
    "\n",
    "    # Perform a fixed number of gradient steps\n",
    "    num_steps = 5000\n",
    "    for step in range(num_steps):\n",
    "        loss = svi.step(data)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Loss for iteration {step}: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze\n",
    "\n",
    "Let's take a look at the learned variational distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thumb_tack_analyze():\n",
    "\n",
    "    # Get the values of the variational parameters\n",
    "    q_alpha = pyro.param(\"q_alpha\").item()\n",
    "    q_beta = pyro.param(\"q_beta\").item()\n",
    "\n",
    "    mean = q_alpha/(q_alpha + q_beta)\n",
    "    std = q_alpha*q_beta/(((q_alpha+q_beta)**2)*(q_alpha + q_beta + 1.0))\n",
    "\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Standard deviation: {std}\")\n",
    "\n",
    "    x = np.linspace(0.0, 1.0, 1000)\n",
    "    plt.plot(x, beta.pdf(x, q_alpha, q_beta))\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The data consists of 20 pin ups ('1') and 80 pin down ('0')\n",
    "data = torch.cat((torch.ones(20, 1), torch.zeros(80, 1)))\n",
    "\n",
    "# Do learning\n",
    "thumb_tack_learn(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumb_tack_analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
